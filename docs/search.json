[
  {
    "objectID": "term-01-midterm-project.html#scenario-interning-at-the-global-risk-observatory-gro",
    "href": "term-01-midterm-project.html#scenario-interning-at-the-global-risk-observatory-gro",
    "title": "Econ 148",
    "section": "Scenario: Interning at the Global Risk Observatory (GRO)",
    "text": "Scenario: Interning at the Global Risk Observatory (GRO)\nYou’ve just landed a midterm internship at the Global Risk Observatory (GRO), an international think tank that advises governments and humanitarian agencies on disaster preparedness and economic resilience. Your team is tasked with analyzing a newly released dataset: the Global Earthquake-Tsunami Risk Assessment Dataset, which contains seismic and tsunami-related data from 782 significant earthquakes worldwide between 2001 and 2022.\nYour supervisor has asked you to process and analyze this dataset using the R programming to generate insights that can inform economic policy, infrastructure investment, and early warning systems.",
    "crumbs": [
      "Midterm & Final projects",
      "Midterm project: Earthquake and tsunami analysis"
    ]
  },
  {
    "objectID": "term-01-midterm-project.html#dataset-description",
    "href": "term-01-midterm-project.html#dataset-description",
    "title": "Econ 148",
    "section": "Dataset Description",
    "text": "Dataset Description\n\n\n\nVariable metadata and tsunami relevance\n\n\n\n\n\n\n\n\n\nFeature\nType\nDescription\nRange / Values\nTsunami relevance\n\n\n\n\nmagnitude\nFloat\nEarthquake magnitude (Richter scale)\n6.5 - 9.1\nHigh — Primary tsunami predictor\n\n\ncdi\nInteger\nCommunity Decimal Intensity (felt intensity)\n0 - 9\nMedium — Population impact measure\n\n\nmmi\nInteger\nModified Mercalli Intensity (instrumental)\n1 - 9\nMedium — Structural damage indicator\n\n\nsig\nInteger\nEvent significance score\n650 - 2910\nHigh — Overall hazard assessment\n\n\nnst\nInteger\nNumber of seismic monitoring stations\n0 - 934\nLow — Data quality indicator\n\n\ndmin\nFloat\nDistance to nearest seismic station (degrees)\n0.0 - 17.7\nLow — Location precision\n\n\ngap\nFloat\nAzimuthal gap between stations (degrees)\n0.0 - 239.0\nLow — Location reliability\n\n\ndepth\nFloat\nEarthquake focal depth (km)\n2.7 - 670.8\nHigh — Shallow = higher tsunami risk\n\n\nlatitude\nFloat\nEpicenter latitude (WGS84)\n−61.85° to 71.63°\nHigh — Ocean proximity indicator\n\n\nlongitude\nFloat\nEpicenter longitude (WGS84)\n−179.97° to 179.66°\nHigh — Ocean proximity indicator\n\n\nYear\nInteger\nYear of occurrence\n2001 - 2022\nMedium — Temporal patterns\n\n\nMonth\nInteger\nMonth of occurrence\n1 - 12\nLow — Seasonal analysis\n\n\ntsunami\nBinary\nTsunami potential (TARGET)\n0, 1\nTarget variable",
    "crumbs": [
      "Midterm & Final projects",
      "Midterm project: Earthquake and tsunami analysis"
    ]
  },
  {
    "objectID": "term-01-midterm-project.html#your-mission-complete-the-following-tasks",
    "href": "term-01-midterm-project.html#your-mission-complete-the-following-tasks",
    "title": "Econ 148",
    "section": "Your mission: complete the following tasks:",
    "text": "Your mission: complete the following tasks:\nUse R and ggplot2 to complete each task. Submit your code and visual outputs with brief explanations.\n\nLoad and inspect the Dataset\n\nLoad the CSV file into R.\nUse str(), summary(), and head() to inspect the structure and contents.\nIdentify the number of tsunami vs. non-tsunami events.\n\nEarthquake magnitude distribution\n\nCreate a histogram of earthquake magnitudes using ggplot2\nAdd appropriate axis labels and title.\nBriefly describe the distribution.\n\nTsunami event proportion\n\nCreate a bar chart showing the count of tsunami vs. non-tsunami events.\nUse ggplot2 and customize colors.\nWhat percentage of events are tsunami-related?\n\nEarthquake frequency by year\n\nCreate a line plot showing the number of earthquakes per year.\nUse geom_line() or geom_col() with year as the x-axis\nIdentify any years with spikes in activity.\n\nLatitude vs. longitude plot\n\nCreate a scatter plot of earthquake epicenters using latitude and longitude.\nColor-code points by tsunami potential (0 or 1).\nWhat regions appear most tsunami-prone?\n\nDepth vs. magnitude\n\nCreate a scatter plot of earthquake depth vs. magnitude\nUse color or shape to distinguish tsunami events.\nDiscuss any patterns you observe.\n\nIntensity comparison\n\nUse boxplots to compare cdi (Community Decimal Intensity) between tsunami and non-tsunami events.\nWhat does this suggest about population impact?\n\nAnnotated insight\n\nChoose one plot and add annotations using geom_text() or geom_label() to highlight key insights.\nExplain why this insight matters for economic planning.\n\nSave your visuals\n\nSave at least three plots as PNG files using ggsave().\nInclude filenames and dimensions in your code.\n\nReflection\n\nWrite a short reflection (150–200 words) on how data visualization can support disaster resilience and economic decision-making.",
    "crumbs": [
      "Midterm & Final projects",
      "Midterm project: Earthquake and tsunami analysis"
    ]
  },
  {
    "objectID": "term-01-midterm-project.html#midterm-files-and-submission",
    "href": "term-01-midterm-project.html#midterm-files-and-submission",
    "title": "Econ 148",
    "section": "Midterm files and submission:",
    "text": "Midterm files and submission:\n\nAccess the midterm R script and dataset from this link: Midterm Project Files\nSubmit your midterm exam answer sheet (R script with code, plots, and explanations) via google form: Midterm Submission Form\nDeadline: November 3, 2025, 11:59 PM PST",
    "crumbs": [
      "Midterm & Final projects",
      "Midterm project: Earthquake and tsunami analysis"
    ]
  },
  {
    "objectID": "m6-test-means.html",
    "href": "m6-test-means.html",
    "title": "Module 6: Tests on means and chi-square test",
    "section": "",
    "text": "Introduction to hypothesis testing\nParametric vs non-parametric tests\nIndependent samples t-test\nPaired samples t-test\nOne-way ANOVA\nChi-square test\n\nView slides in new window\n\n\n\n\n\n\n\n\n\n\nPresentation keyboard shortcuts\n\n\n\n\n\n\nUse ← and → to navigate through the slides\n\n\nUse F to toggle full screen\n\n\nUse O to view an overview of all slides\n\n\nUse ? to see a list of other shortcuts"
  },
  {
    "objectID": "m4-survey-research-design.html",
    "href": "m4-survey-research-design.html",
    "title": "Module 4: Survey research design",
    "section": "",
    "text": "Methods of data collection\nSampling desing in surveys\nMeasurement issues in survey research\nQuestionnaire construction\nBasics of interviewing\nCreating codebook\nData entry\n\nView slides in new window\n\n\n\n\n\nPresentation keyboard shortcuts\n\n\n\nUse ← and → to navigate through the slides\n\n\nUse F to toggle full screen\n\n\nUse O to view an overview of all slides\n\n\nUse ? to see a list of other shortcuts"
  },
  {
    "objectID": "m2-intro-data-viz-ggplot.html",
    "href": "m2-intro-data-viz-ggplot.html",
    "title": "Module 2: Intro to data visualization using ggplot2",
    "section": "",
    "text": "The grammar of graphics\nDatasets and mapping\nGeometries\nStatistical transformation and plotting distribution\nPosition adjustment and scales\nCoordinates and themes\nFacets and custom plots\nView slides in new window",
    "crumbs": [
      "Topics",
      "Module 2: Intro to data visualization using ggplot2"
    ]
  },
  {
    "objectID": "m2-intro-data-viz-ggplot.html#class-demonstration",
    "href": "m2-intro-data-viz-ggplot.html#class-demonstration",
    "title": "Module 2: Intro to data visualization using ggplot2",
    "section": "Class demonstration",
    "text": "Class demonstration\n\nLine plot: baby names\n\n\n## libraries\nlibrary(tidyverse)\nlibrary(babynames)\n\n## my male friends\nmy_male_friends_data &lt;- \n  babynames %&gt;% \n  filter(name %in% c(\"Christopher\", \"Vincent\", \"John\", \"Marvin\")) %&gt;% \n  filter(sex == \"M\")\n\n\n### line plot\nggplot(data = my_male_friends_data, \n       mapping = aes(x = year, y = n, color = name)) +\n  geom_line() +\n  geom_point() +\n  scale_y_log10() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n## my female friends\nmy_female_friends_data &lt;- \n  babynames %&gt;% \n  filter(name %in% c(\"Jane\", \"Mariah\", \"Marian\", \"Sarah\")) %&gt;% \n  filter(sex == \"F\")\n\n## line plot\nggplot(data = my_female_friends_data, \n       mapping = aes(x = year, y = n, color = name)) +\n  geom_line() +\n  geom_point() +\n  scale_y_log10() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nScatter plot\n\n\n## average fuel consumption\nmean_hwy_data &lt;- \n  mpg %&gt;% \n  group_by(class) %&gt;% \n  summarise(mean_hwy = mean(hwy, na.rm = TRUE))\n\n## scatter plot\nggplot(data = mpg, \n       mapping = aes(x = class, y = hwy, color = class)) +\n  geom_point(position = position_jitter(width = 0.2), size = 2.5, alpha = 0.4) +\n  geom_point(data = mean_hwy_data, aes(y = mean_hwy), size = 5) +\n  labs(title = \"Fuel consumption per class vehicle\",\n       x = \"Class of vehicle\",\n       y = \"Highway fuel consumption\") +\n  theme_minimal() +\n  theme(panel.grid = element_line(color = \"gray80\"),\n        plot.margin = margin(rep(20, 4)),\n        plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"),\n        axis.title.x = element_text(margin = margin(t = 20)),\n        axis.title.y = element_text(margin = margin(r = 20))\n        )",
    "crumbs": [
      "Topics",
      "Module 2: Intro to data visualization using ggplot2"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Econ 148: Analytical and statistical packages for economics 1",
    "section": "",
    "text": "Class schedule: Wednesday | 13:00 - 15:00  Laboratory schedule: Wednesday | 16:00 - 19:00  Instructor: Christopher Llones  e-mail: christopher.llones@vsu.edu.ph  Pre-requisites: Econ 115 - Econometrics  Course credits: 3 units  Number of hours: 2 hrs lectures and 3 hrs laboratory per week \n\n\nCourse description\nIntroduction to survey research and survey data analysis using R programming.\n\n\nCourse objectives\n\nCreate a valid and reliable survey questionnaire and survey codebook.\nPerform exploratory data analysis on survey data using R programming.\nPerform Parametric and Non-Parametric Test on Means using R.\nPerform correlation analysis and build a regression model explaining relationship of certain economic variables in R.\nPerform regression analysis on limited dependent variables in R.\nPerform various techniques of multivariate data analysis in the R statistical software.\n\n\n\nCourse outline\n\n\n\n\n\n\n\n\nTopics\nLessons\nDescription\n\n\n\n\nModule 1: Introduction to R Programming\n\nInstalling R and RStudio\nR Basics\nWorking with R scripts\nImporting data\nBasic data wrangling\n\n\nLearn to install and configure R and RStudio.\nUnderstand and apply basic R syntax including data types, vectors, and data frames.\nDevelop proficiency in writing, saving, and executing R scripts.\nImport dataset and prepare them for analysis.\nClean and transform data .\n\n\n\nModule 2: Introduction to data visualization using ggplot2\n\nUnderstanding grammar of graphics\nDataset and mapping\nGeometries\nStatistical transformation and plotting distribution\nPosition adjustment and scales\n\n\nUnderstand the grammar of graphics and its role in structuring visualizations.\nCreate and customize basic plots including histograms, bar charts, boxplots, and scatterplot.\nMap variables to visual aesthetics such as color, shape, and size to enhance interpretability.\nApply faceting techniques to produce multi-panel plots for comparative analysis.\nModify plot themes and coordinate systems to improve clarity and accessibility.\nExport visualizations for use in reports, presentations, policy briefs, and others.\n\n\n\nModule 3: Reproducible report with Quarto in R\n\nIntroduction to Quarto\nCreating Quarto document\nEmbedding R code\nFormatting Outputs\nExporting reports\n\n\nLearn to create dynamic, reproducible documents using Quarto and markdown syntax.\nEmbed R code and inline calculations within narrative text to integrate analysis and interpretation.\nFormat outputs such as tables and plots for professional presentation.\nRender reports to multiple formats including HTML, PDF, and Word for diverse audiences.\nDevelop the ability to produce transparent, replicable research outputs for academic and policy contexts.\n\n\n\nModule 1: survey research design\n\nMethods of data collection\nSampling design in surveys\nMeasurement issues in survey research\nQuestionnaire construction\nBasics of interviewing\nCreating a codebook\nData entry\n\n\nDiscuss the various methods of data collection including survey, observation and experimental methods.\nDiscuss different ways for gathering a sample; random and non-random sampling. Discuss rudimentary formulas for sample size calculation.\nDiscuss the issues in assigning numbers to represent quantities of attributes. Discuss the various scales of measurement. Discuss criteria in constructing good measurement of variables: reliablity and validity.\nDiscuss the various advantages and disadvantages of interviews and questionnaire over other methods of data collection.\nDiscuss the do’s and dont’s of an interviewer’s conduct.\nDiscuss the importance of creating a codebook for survey data.\nDiscuss rudimentary of data entry.\n\n\n\nModule 2: exploratory data analysis\n\nRudiments of EDA\nCharts and tables\nMeasures of central tendency\nDispersion, parameters, skewness and kurtosis\nContingency tables and scatter plot\n\n\nDiscuss EDA as the first step in data analysis.\nDiscuss various techniques in summarizing and visualizing data.\nDiscuss the various measures of central tendency and data location.\nDiscuss the relevance of various dispersion, parameters, skewness and kurtosis.\nDiscuss the relevance of contingency tables and scatterplots for summarizing and visualizing data.\n\n\n\nModule 3: test on means\n\nParametric test on means\nNon-parametric test on means\n\n\nDiscuss the various t-tests and ANOVA and perform them on a sample data with R.\nPerform various non-parametric equivalent of the t-tests and ANOVA on sample data with R.\n\n\n\nModule 4: correlation and regression analysis\n\nCorrelation analysis\nReview of Regression analysis\n\n\nDiscuss the various types of correlation analysis procedures. Interpret the correlation coefficient.\nDiscuss the various aspects of regression model building.\n\n\n\nModule 5: limited-dependent variable models\n\nReview of binary dependent regression\nExtension to the logit model.\nCensored and truncated regression models.\nCount dependent variable models.\n\n\nDiscuss the various aspects of the logit and probit.\nDiscuss the multinomial and ordinal logit models.\nDiscuss the Tobit regression model for censored data and truncated regression models.\nDiscuss Poisson and Negative Binomial regression models in the regression analysis of count-dependent variable models.\n\n\n\nModule 6: multivariate statistical analysis\n\nCluster analysis\nPrincipal component analysis\nExploratory factor analysis\nConfirmatory factor anlysis\nStructural equation modelling\n\n\nUnderstand and apply different clustering methods. Analyze and evaluate the quality and effectiveness of different clusters in dataset.\nLearn to perform and interpret principal component analysis to reduce the dimensionality of dataset. Develop the ability to identify and retain significant components for simplifying data without losing critical information.\nIdentify and estimate underlying factor structures within a set of observed variables.\nUnderstand model-based factor anlaysis and develop proficiency in evaluating model fit and making necessary adjustments to improve analysis.\nApply SEM techniques to understand relationships among variables and construct theoretical models.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "01-assignment-1-e-commerce.html",
    "href": "01-assignment-1-e-commerce.html",
    "title": "Econ 148",
    "section": "",
    "text": "Course title: Econ148: Analytical and statistical packages for economics 1  Instructor: Christopher Llones  Assignment: E-commerce sales dataset analysis in R  Due Date: 15 October 2025",
    "crumbs": [
      "Assignment",
      "Module 1 assignment"
    ]
  },
  {
    "objectID": "01-assignment-1-e-commerce.html#objective",
    "href": "01-assignment-1-e-commerce.html#objective",
    "title": "Econ 148",
    "section": "Objective",
    "text": "Objective\nThis assignment will strengthen your ability to analyze economic data using R. You’ll work with a synthetic but realistic dataset of e-commerce transactions from 2024–2025. Your goal is to apply dplyr and other relevant packages to explore sales patterns, profit margins, and regional trends.",
    "crumbs": [
      "Assignment",
      "Module 1 assignment"
    ]
  },
  {
    "objectID": "01-assignment-1-e-commerce.html#instructions",
    "href": "01-assignment-1-e-commerce.html#instructions",
    "title": "Econ 148",
    "section": "Instructions",
    "text": "Instructions\n\nUse R and the dplyr package to answer each question.\nSubmit your R script file (.R) with your code and outputs.\nUse the pipe operator (%&gt;%) for all data manipulations.\nYou may use additional packages like ggplot2, lubridate, or stringr if needed.\nEnsure your code is clean, commented, and reproducible.\n\n\n\n\n\n\n\nDataset and files\n\n\n\n\nAccess the dataset and R script template from the econ148-assignment1 folder.\nSubmit your completed R script file (.R) by the due date and upload using this link: Submission Link.",
    "crumbs": [
      "Assignment",
      "Module 1 assignment"
    ]
  },
  {
    "objectID": "01-assignment-1-e-commerce.html#questions",
    "href": "01-assignment-1-e-commerce.html#questions",
    "title": "Econ 148",
    "section": "Questions",
    "text": "Questions\nPart 1: Data familiarization\n\nHow many rows and columns are in the dataset?\nList all unique product categories and sub-categories.\nWhat are the earliest and latest order dates?\n\nPart 2: sales and profit analysis\n\nWhat is the total sales and total profit across all transactions?\nWhich region generated the highest total profit?\nWhat is the average discount applied across all orders?\n\nPart 3: produce performance\n\nWhich product had the highest total sales?\nWhich sub-category had the lowest average profit per unit sold?\nIdentify the top 5 cities by total sales.\n\nPart 4: time series and trend analysis\n\nGroup the data by month and summarize total sales and profit.\nWhich month had the highest sales volume?\nPlot a time series of monthly sales using ggplot2.\n\nBonus Challenge\n\nCreate a new column for profit margin (profit as a percentage of sales). Then, find the average profit margin by region.\nIdentify any product with a negative profit margin and explain possible reasons.",
    "crumbs": [
      "Assignment",
      "Module 1 assignment"
    ]
  },
  {
    "objectID": "01-assignment-1-e-commerce.html#grading-rubrics",
    "href": "01-assignment-1-e-commerce.html#grading-rubrics",
    "title": "Econ 148",
    "section": "Grading rubrics",
    "text": "Grading rubrics\n\n\n\n\n\n\n\n\n\n\nCriteria\nExcellent (5pts)\nGood (4pts)\nFair (2-3 pts)\nNeeds improvement (0-1 pt)\n\n\n\n\nCode accuracy\nAll answers are correct and match expected outputs.\nMost answers are correct with minor errors.\nSeveral answers are incorrect or incomplete.\nMany answers are missing or incorrect.\n\n\nUse of dplyr Functions\nConsistently uses appropriate dplyr verbs (filter, mutate, summarise, etc.).\nUses dplyr functions correctly in most cases.\nUses some dplyr functions but inconsistently or incorrectly.\nRarely uses dplyr or misuses functions.\n\n\nPipe Operator Usage (%&gt;%)\nPipe operator is used fluently and correctly throughout.\nMostly correct usage with occasional syntax issues.\nUsed sporadically or with frequent errors.\nNot used or used incorrectly.\n\n\nData Manipulation & Filtering\nDemonstrates strong understanding of filtering, grouping, and summarizing.\nShows good grasp with minor gaps.\nBasic filtering and grouping attempted but lacks depth.\nLittle to no meaningful data manipulation.\n\n\nInsight & Interpretation\nProvides thoughtful insights or observations where applicable.\nSome interpretation is present.\nMinimal interpretation or unclear reasoning.\nNo interpretation or irrelevant commentary.\n\n\nBonus Challenge (Q13–Q14)\nCompleted with correct logic and creative approach.\nAttempted with mostly correct logic.\nAttempted but contains errors or lacks clarity.\nNot attempted or incorrect.\n\n\nReproducibility\nCode runs without errors and produces expected results.\nMinor issues but generally reproducible.\nSome errors prevent full reproducibility.\nCode fails to run or produces major errors.",
    "crumbs": [
      "Assignment",
      "Module 1 assignment"
    ]
  },
  {
    "objectID": "00-m0-midterm-project.html#instructions",
    "href": "00-m0-midterm-project.html#instructions",
    "title": "Econ 148",
    "section": "Instructions",
    "text": "Instructions\nWelcome to the midterm project exercise! In this exercise, you will work on a project that involves analyzing employee attrition and performance using the HR Analytics Employee Attrition & Performance dataset. The primary goal is to develop insights into the factors that contribute to employee attrition and provide recommendations for HR interventions that could help reduce attrition and improve overall employee satisfaction and performance.\nDownload the project files using this link: Midterm project files. Be sure to download the entire folder midterm-econ148-project-exercise. The project files include the dataset and a template Quarto markdown file that you will use to complete the exercise.\nFirst, rename the lastname-firstname.qmd file to your actual last name and first name. For example, if your name is John Doe, the file should be named doe-john.qmd. Afterward, open the R project 20241007-econ148-project-exercise-1.Rproj by double-clicking the file and render the Quarto markdown file to generate the HTML file."
  },
  {
    "objectID": "00-m0-midterm-project.html#project-overiew",
    "href": "00-m0-midterm-project.html#project-overiew",
    "title": "Econ 148",
    "section": "Project overiew",
    "text": "Project overiew\nIn this project, we will explore employee attrition and performance using the HR Analytics Employee Attrition & Performance dataset. The primary goal is to develop insights into the factors that contribute to employee attrition.\nThe dataset used for this project provides information about employee demographics, performance metrics, and various satisfaction ratings. By analyzing a range of factors, including demographic data, job satisfaction, work-life balance, and job role, we aim to help businesses identify key areas where they can improve employee retention.\n\n## datatable function from DT package create an HTML widget display of the dataset\n## install DT package if the package is not yet available in your R environment\nreadxl::read_excel(\"dataset/dataset-variable-description.xlsx\") |&gt; \n  DT::datatable()"
  },
  {
    "objectID": "00-m0-midterm-project.html#data-wrangling-and-management",
    "href": "00-m0-midterm-project.html#data-wrangling-and-management",
    "title": "Econ 148",
    "section": "Data wrangling and management",
    "text": "Data wrangling and management\n\nLibraries\n\n\n\n\n\n\nTask: Load the necessary libraries\n\n\n\nBefore we start working on the dataset, we need to load the necessary libraries that will be used for data wrangling, analysis and visualization. Make sure to load the following libraries here. For packages to be installed, you can use the install.packages function. There are packages to be installed later on this project, so make sure to install them as needed and load them here.\n\n\n\n# load all your libraries here\n\n\n\nData importation\n\n\n\n\n\n\nTask 2.1. Merging dataset\n\n\n\n\nImport the two dataset Employee.csv and PerformanceRating.csv. Save the Employee.csv as employee_dta and PerformanceRating.csv as perf_rating_dta.\nMerge the two dataset using the left_join function from dplyr. Use the EmployeeID variable as the varible to join by. You may read more information about the left_join function here.\nSave the merged dataset as hr_perf_dta and display the dataset using the datatable function from DT package.\n\n\n\n\n## import the two data here\n\n\n## merge employee_dta and perf_rating_dta using left_join function.\n## save the merged dataset as hr_perf_dta\n\n\n\n## Use the datatable from DT package to display the merged dataset\n\n\n\nData management\n\n\n\n\n\n\nTask 2.2. Standardizing variable names\n\n\n\n\nUsing the clean_names function from janitor package, standardize the variable names by using the recommended naming of variables.\nSave the renamed variables as hr_perf_dta to update the dataset.\n\n\n\n\n## clean names using the janitor packages and save as hr_perf_dta\n\n\n## display the renamed hr_perf_dta using datatable function\n\n\n\n\n\n\n\nTask 2.3. Recode data entries\n\n\n\n\nCreate a new variable cat_education wherein education is 1 = No formal education; 2 = High school; 3 = Bachelor; 4 = Masters; 5 = Doctorate. Use the case_when function to accomplish this task.\nSimilarly, create new variables cat_envi_sat, cat_job_sat, and cat_relation_sat for environment_satisfaction, job_satisfaction, and relationship_satisfaction, respectively. Re-code the values accordingly as 1 = Very dissatisfied; 2 = Dissatisfied; 3 = Neutral; 4 = Satisfied; and 5 = Very satisfied.\nCreate new variables cat_work_life_balance, cat_self_rating, cat_manager_rating for work_life_balance, self_rating, and manager_rating, respectively. Re-code accordingly as 1 = Unacceptable; 2 = Needs improvement; 3 = Meets expectation; 4 = Exceeds expectation; and 5 = Above and beyond.\nCreate a new variable bi_attrition by transforming attrition variable as a numeric variabe. Re-code accordingly as No = 0, and Yes = 1.\nSave all the changes in the hr_perf_dta. Note that saving the changes with the same name will update the dataset with the new variables created.\n\n\n\n\n## create cat_education\n\n\n\n## create cat_envi_sat,  cat_job_sat, and cat_relation_sat\n\n\n\n\n## create cat_work_life_balance, cat_self_rating, and cat_manager_rating\n\n\n\n\n\n## create bi_attrition\n\n\n\n## print the updated hr_perf_dta using datatable function"
  },
  {
    "objectID": "00-m0-midterm-project.html#exploratory-data-analysis",
    "href": "00-m0-midterm-project.html#exploratory-data-analysis",
    "title": "Econ 148",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nDescriptive statistics of employee attrition\n\n\n\n\n\n\nTask 3.1. Breakdown of attrition by key variables\n\n\n\n\nSelect the variables attrition, job_role, department, age, salary, job_satisfaction, and work_life_balance. Save as attrition_key_var_dta.\nCompute and plot the attrition rate across job_role, department, and age, salary, job_satisfaction, and work_life_balance. To compute for the attrition rate, group the dataset by job role. Afterward, you can use the count function to get the frequency of attrition for each job role and then divide it by the total number of observations. Save the computation as pct_attrition. Do not forget to ungroup before storing the output. Store the output as attrition_rate_job_role.\nPlot for the attrition rate across job_role has been done for you! Study each line of code. You have the freedom to customize your plot accordingly. Show your creativity!\n\n\n\n\n## selecting attrition key variables and save as `attrition_key_var_dta`\n\n\n\n\n## compute the attrition rate across job_role and save as attrition_rate_job_role\n\n\n\n## print attrition_rate_job_role\n\n\n## Plot the attrition rate\n\n\n\nAnalysis of compensation and turnover\n\n\n\n\n\n\nTask 3.2. Analyzing compensation and turnover\n\n\n\n\nCompare the average monthly income of employees who left the company (bi_attrition = 1) and those who stayed (bi_attrition = 0). Use the t.test function to conduct a t-test and determine if there is a significant difference in average monthly income between the two groups. Save the results in a variable called attrition_ttest_results.\nInstall the report package and use the report function to generate a report of the t-test results.\nInstall the ggstatsplot package and use the ggbetweenstats function to visualize the distribution of monthly income for employees who left and those who stayed. Make sure to map the bi_attrition variable to the x argument and the salary variable to the y argument.\nVisualize the salary variable for employees who left and those who stayed using geom_histogram with geom_freqpoly. Make sure to facet the plot by the bi_attrition variable and apply alpha on the histogram plot.\nProvide recommendations on whether revising compensation policies could be an effective retention strategy.\n\n\n\n\n## compare the average monthly income of employees who left and those who stayed\n\n\n\n\n## print the results of the t-test\n\n\n## install the report package and use the report function to generate a report of the t-test results\n\n\n# install ggstatsplot package and use ggbetweenstats function to visualize the distribution of monthly income for employees who left and those who stayed\n\n\n# create histogram and frequency polygon of salary for employees who left and those who stayed\n\n\n\n\n\n\n\nDiscussion:\n\n\n\nProvide your discussion here.\n\n\n\n\nEmployee satisfaction and performance analysis\n\n\n\n\n\n\nTask 3.3. Analyzing employee satisfaction and performance\n\n\n\n\nAnalyze the average performance ratings (both ManagerRating and SelfRating) of employees who left vs. those who stayed. Use the group_by and count functions to calculate the average performance ratings for each group.\nVisualize the distribution of SelfRating for employees who left and those who stayed using a bar plot. Use the ggplot function to create the plot and map the SelfRating variable to the x argument and the bi_attrition variable to the fill argument.\nSimilarly, visualize the distribution of ManagerRating for employees who left and those who stayed using a bar plot. Make sure to map the ManagerRating variable to the x argument and the bi_attrition variable to the fill argument.\nCreate a boxplot of salary by job_satisfaction and bi_attrition to analyze the relationship between salary, job satisfaction, and attrition. Use the geom_boxplot function to create the plot and map the salary variable to the x argument, the job_satisfaction variable to the y argument, and the bi_attrition variable to the fill argument. You need to transform the job_satisfaction and bi_attrition variables into factors before creating the plot or within the ggplot function.\nDiscuss the results of the analysis and provide recommendations for HR interventions based on the findings.\n\n\n\n\n# Analyze the average performance ratings (both ManagerRating and SelfRating) of employees who left vs. those who stayed.\n\n\n# Visualize the distribution of SelfRating for employees who left and those who stayed using a bar plot.\n\n\n# Visualize the distribution of ManagerRating for employees who left and those who stayed using a bar plot.\n\n\n# create a boxplot of salary by job_satisfaction and bi_attrition to analyze the relationship between salary, job satisfaction, and attrition.\n\n\n\n\n\n\n\nDiscussion:\n\n\n\nProvide your discussion here.\n\n\n\n\nWork-life balance and retention strategies\n\n\n\n\n\n\nTask 3.4. Analyzing work-life balance and retention strategies\n\n\n\nAt this point, you are already well aware of the dataset and the possible factors that contribute to employee attrition. Using your R skills, accomplish the following tasks:\n\nAnalyze the distribution of WorkLifeBalance ratings for employees who left versus those who stayed.\nUse visualizations to show the differences.\nAssess whether employees with poor work-life balance are more likely to leave.\n\nYou have the freedom how you will accomplish this task. Be creative and provide insights that will help HR develop effective retention strategies."
  },
  {
    "objectID": "01-course-outline.html",
    "href": "01-course-outline.html",
    "title": "Course outline",
    "section": "",
    "text": "Week\nTopics\nLessons\nActivities\n\n\n\n\nWeek 1-2\nFoundation of academic writing\n\nOverview of academic writing genres and their purposes.\nDiscussion of the key principles of academic writing.\nIntroduction to the structure of academic papers.\n\n\n\n\nWeek 3-4\nDeveloping research methods\n\nFormulating research topics and research questions.\nIdentifying relevant literature and conducting a literature review.\nDeveloping a thesis statement and creating an outline for a research paper.\n\n\n\n\nWeek 5-6\nWriting first darf\n\nWriting effective introductions and conclusions.\nCrafting clear and concise methods and results section.\nWriting persuasive literature and discussions.\nUsing appropriate language and tone in academic writing.\n\n\n\n\nWeek 7-8\nRevising and editing\n\nStrategies for revising and editing academic writing.\nPeer review and feedback exercises.\nUsing tools and resources for editing and proofreading.\n\n\n\n\nWeek 9-10\nNavigating peer-review process\n\nOverview of the peer-review process in academic publishing.\nSelecting appropriate journals for submission.\nPreparing manuscripts for submission.\nResponding to reviewer feedback and revising manuscripts.\n\n\n\n\nWeek 11-12\nEthical considerations in publishing\n\nDiscussion of plagiarism, authorship, and other ethical issues in academic publishing.\nIntroduction to copyright and intellectual property.\nExploration of open access and alternative publishing models.\n\n\n\n\nWeek 13-14\nConference presentation and other scholarly outputs\n\nPreparing and delivering effective conference presentations.\nWriting conference abstracts and proposal.\nExploring other scholarly outputs.\n\n\n\n\nWeek 15-16\nFinal project presentations and discussion\n\nPresentation of final research papers and other scholarly projects.\nDiscussion and feedback from peers and instructor.\nReflections on the course and future goals in academic writing and publishing."
  },
  {
    "objectID": "m1-intro-r.html",
    "href": "m1-intro-r.html",
    "title": "Module 1: Intro to R programming",
    "section": "",
    "text": "R objects\nR packages\nReading data in R\nBasic data wrangling\nView slides in new window",
    "crumbs": [
      "Topics",
      "Module 1: Introduction to R programming"
    ]
  },
  {
    "objectID": "m1-intro-r.html#exercises",
    "href": "m1-intro-r.html#exercises",
    "title": "Module 1: Intro to R programming",
    "section": "Exercises",
    "text": "Exercises\n\nInstall R and RStudio on your computer.\nDownload the entire folder 00-module-intro-r from the Google Drive link. For the meantime, keep the folder in your computer and wait for further instructions during the class.\nBefore the class start, open the RStudio and paste the following code in the console to install the required packages. Just click the clipboard icon to copy the code.\n\n\n## install required packages\ninstall.packages(c(\"janitor\", \"readxl\", \"haven\", \"tidyverse\", \"skimr\"))\n\n\n\n\n\n\n\nImportant\n\n\n\nPlease make sure to install the required packages before the class starts, as we may not have a secure internet connection. If you encounter any issues, please let me know.",
    "crumbs": [
      "Topics",
      "Module 1: Introduction to R programming"
    ]
  },
  {
    "objectID": "m3-reproducible-quarto.html",
    "href": "m3-reproducible-quarto.html",
    "title": "Module 3: Reproducible report with Quarto in R",
    "section": "",
    "text": "Introduction to Quarto\nQuarto document elements\nExercise: generating reports\nImproving report\n\nView slides in new window\n\n\n\n\n\nPresentation keyboard shortcuts\n\n\n\nUse ← and → to navigate through the slides\n\n\nUse F to toggle full screen\n\n\nUse O to view an overview of all slides\n\n\nUse ? to see a list of other shortcuts"
  },
  {
    "objectID": "m5-exploratory-data-analysis.html",
    "href": "m5-exploratory-data-analysis.html",
    "title": "Module 5: exploratory data analysis",
    "section": "",
    "text": "Overview of EDA\nCentrality and variability\nAmounts and proportions\nComparisons\nTrends\n\nView slides in new window\n\n\n\n\n\n\n\n\n\n\nPresentation keyboard shortcuts\n\n\n\n\n\n\nUse ← and → to navigate through the slides\n\n\nUse F to toggle full screen\n\n\nUse O to view an overview of all slides\n\n\nUse ? to see a list of other shortcuts"
  }
]