[
  {
    "objectID": "m5-exploratory-data-analysis.html",
    "href": "m5-exploratory-data-analysis.html",
    "title": "Module 5: exploratory data analysis",
    "section": "",
    "text": "Overview of EDA\nCentrality and variability\nAmounts and proportions\nComparisons\nTrends\n\nView slides in new window\n\n\n\n\n\n\n\n\n\n\nPresentation keyboard shortcuts\n\n\n\n\n\n\nUse ← and → to navigate through the slides\n\n\nUse F to toggle full screen\n\n\nUse O to view an overview of all slides\n\n\nUse ? to see a list of other shortcuts"
  },
  {
    "objectID": "m3-reproducible-quarto.html",
    "href": "m3-reproducible-quarto.html",
    "title": "Module 3: Reproducible report with Quarto in R",
    "section": "",
    "text": "Introduction to Quarto\nQuarto document elements\nExercise: generating reports\nImproving report\n\nView slides in new window\n\n\n\n\n\nPresentation keyboard shortcuts\n\n\n\nUse ← and → to navigate through the slides\n\n\nUse F to toggle full screen\n\n\nUse O to view an overview of all slides\n\n\nUse ? to see a list of other shortcuts"
  },
  {
    "objectID": "m1-intro-r.html",
    "href": "m1-intro-r.html",
    "title": "Module 1: Intro to R programming",
    "section": "",
    "text": "R objects\nR packages\nReading data in R\nBasic data wrangling\nView slides in new window",
    "crumbs": [
      "Topics",
      "Module 1: Introduction to R programming"
    ]
  },
  {
    "objectID": "m1-intro-r.html#exercises",
    "href": "m1-intro-r.html#exercises",
    "title": "Module 1: Intro to R programming",
    "section": "Exercises",
    "text": "Exercises\n\nInstall R and RStudio on your computer.\nDownload the entire folder 00-module-intro-r from the Google Drive link. For the meantime, keep the folder in your computer and wait for further instructions during the class.\nBefore the class start, open the RStudio and paste the following code in the console to install the required packages. Just click the clipboard icon to copy the code.\n\n\n## install required packages\ninstall.packages(c(\"janitor\", \"readxl\", \"haven\", \"tidyverse\", \"skimr\"))\n\n\n\n\n\n\n\nImportant\n\n\n\nPlease make sure to install the required packages before the class starts, as we may not have a secure internet connection. If you encounter any issues, please let me know.",
    "crumbs": [
      "Topics",
      "Module 1: Introduction to R programming"
    ]
  },
  {
    "objectID": "m1-intro-r.html#class-demonstration-in-progress",
    "href": "m1-intro-r.html#class-demonstration-in-progress",
    "title": "Module 1: Intro to R programming",
    "section": "Class demonstration in progress",
    "text": "Class demonstration in progress\n\n# INTRO TO R AND BASIC DATA WRANGLING ----\n\n## Install packages\n# install.packages(\"readr\")\n# install.packages(c(\"janitor\", \"readxl\", \"haven\", \"tidyverse\", \"skimr\"))\n\n\n# 1. R Packages ----\nlibrary(readr) # reading csv files\nlibrary(readxl) # reading excel files\nlibrary(haven) # reading spss, sas, stata files\nlibrary(tidyverse) # load all packages under tidyverse environment\nlibrary(dplyr) # for data wrangling\nlibrary(skimr) # quick exploration of your data\nlibrary(janitor) # quick cleaning of dataset\nlibrary(gapminder)\n\n\n# 2. Set the working directory ----\nsetwd(\"D:/Githu-repository/econ148-analytical-stat-packages/148-class-demo/00-module-intro-r\")\n\n\n\n# 3. Reading data into R ----\n\n## 3.1 CSV files\n### Load swimming_pools.csv files using the read_csv() function\nswim_data &lt;- read_csv(\"sample_dataset/swimming_pools.csv\")\nswim_data\n\n### Load potatoes.csv using read_csv() and read.csv()\n#### Observe the difference in the output\n\npotato_data &lt;- read_csv(\"sample_dataset/potatoes.csv\")\npotato_data_2 &lt;- read.csv(\"sample_dataset/potatoes.csv\")\n\nView(potato_data)\n\n\n\n## 3.2 Excel files\n### Load urban_pop files and use the read_xls() and read_excel() functions\n### Save the data into a variable named urban_pop\n\nurban_pop &lt;- read_xls(\"sample_dataset/urbanpop.xls\")\n\n\n\n### Transform the urban_pop data into long-format\n\n\n\n## 3.2 SPSS files\n### Load HBAT.sav\n\nhbat_data &lt;- read_sav(\"sample_dataset/HBAT.sav\")\n\n### Load data from Stata online @ https://www.stata-press.com/data/r9/u.html\n### Use the link http://www.stata-press.com/data/r9/auto.dta and save the data into a variable named auto\n\nauto_data &lt;- read_dta(\"http://www.stata-press.com/data/r9/auto.dta\")\n\n\n## 3.3 Load SAS data\n### Read the SAS data from the eventrepository.sas7bdat file\n### Clean the variable names using the clean_names() function from janitor package\n\nevent_data &lt;- read_sas(\"sample_dataset/eventrepository.sas7bdat\")\nevent_data &lt;- clean_names(event_data)\n\n# 4. Basic data wrangling with tidyverse ----\n### Use gapminder dataset from gapminder package and save it into a variable named gapminder_data\n\ngapminder_data &lt;- gapminder::gapminder\n\n## 4.1 filter() ----\n### Using the gapminder_data, filter dataset for the year 1957\ngapminder_1957 &lt;- filter(gapminder_data, year == 1957)\n\n\n### Now, filter for Philippines in 2002\nfilter(gapminder_data, year &lt; 2000, country == \"Philippines\")\nfilter(gapminder_data, country == \"Philippines\")\n\n### Filter for the year 1957, then arrange in descending order of population\nfilter(gapminder_data, year == 1957)\n\narrange(filter(gapminder_data, year == 1957), desc(pop))\n\ngapminder_data |&gt; \n  filter(year == 1957) |&gt; \n  arrange(pop)\n\n\n\n## 4.2 mutate() ----\n### Use mutate to compute for GDP",
    "crumbs": [
      "Topics",
      "Module 1: Introduction to R programming"
    ]
  },
  {
    "objectID": "01-course-outline.html",
    "href": "01-course-outline.html",
    "title": "Course outline",
    "section": "",
    "text": "Week\nTopics\nLessons\nActivities\n\n\n\n\nWeek 1-2\nFoundation of academic writing\n\nOverview of academic writing genres and their purposes.\nDiscussion of the key principles of academic writing.\nIntroduction to the structure of academic papers.\n\n\n\n\nWeek 3-4\nDeveloping research methods\n\nFormulating research topics and research questions.\nIdentifying relevant literature and conducting a literature review.\nDeveloping a thesis statement and creating an outline for a research paper.\n\n\n\n\nWeek 5-6\nWriting first darf\n\nWriting effective introductions and conclusions.\nCrafting clear and concise methods and results section.\nWriting persuasive literature and discussions.\nUsing appropriate language and tone in academic writing.\n\n\n\n\nWeek 7-8\nRevising and editing\n\nStrategies for revising and editing academic writing.\nPeer review and feedback exercises.\nUsing tools and resources for editing and proofreading.\n\n\n\n\nWeek 9-10\nNavigating peer-review process\n\nOverview of the peer-review process in academic publishing.\nSelecting appropriate journals for submission.\nPreparing manuscripts for submission.\nResponding to reviewer feedback and revising manuscripts.\n\n\n\n\nWeek 11-12\nEthical considerations in publishing\n\nDiscussion of plagiarism, authorship, and other ethical issues in academic publishing.\nIntroduction to copyright and intellectual property.\nExploration of open access and alternative publishing models.\n\n\n\n\nWeek 13-14\nConference presentation and other scholarly outputs\n\nPreparing and delivering effective conference presentations.\nWriting conference abstracts and proposal.\nExploring other scholarly outputs.\n\n\n\n\nWeek 15-16\nFinal project presentations and discussion\n\nPresentation of final research papers and other scholarly projects.\nDiscussion and feedback from peers and instructor.\nReflections on the course and future goals in academic writing and publishing."
  },
  {
    "objectID": "00-m0-midterm-project.html#instructions",
    "href": "00-m0-midterm-project.html#instructions",
    "title": "Econ 148",
    "section": "Instructions",
    "text": "Instructions\nWelcome to the midterm project exercise! In this exercise, you will work on a project that involves analyzing employee attrition and performance using the HR Analytics Employee Attrition & Performance dataset. The primary goal is to develop insights into the factors that contribute to employee attrition and provide recommendations for HR interventions that could help reduce attrition and improve overall employee satisfaction and performance.\nDownload the project files using this link: Midterm project files. Be sure to download the entire folder midterm-econ148-project-exercise. The project files include the dataset and a template Quarto markdown file that you will use to complete the exercise.\nFirst, rename the lastname-firstname.qmd file to your actual last name and first name. For example, if your name is John Doe, the file should be named doe-john.qmd. Afterward, open the R project 20241007-econ148-project-exercise-1.Rproj by double-clicking the file and render the Quarto markdown file to generate the HTML file."
  },
  {
    "objectID": "00-m0-midterm-project.html#project-overiew",
    "href": "00-m0-midterm-project.html#project-overiew",
    "title": "Econ 148",
    "section": "Project overiew",
    "text": "Project overiew\nIn this project, we will explore employee attrition and performance using the HR Analytics Employee Attrition & Performance dataset. The primary goal is to develop insights into the factors that contribute to employee attrition.\nThe dataset used for this project provides information about employee demographics, performance metrics, and various satisfaction ratings. By analyzing a range of factors, including demographic data, job satisfaction, work-life balance, and job role, we aim to help businesses identify key areas where they can improve employee retention.\n\n## datatable function from DT package create an HTML widget display of the dataset\n## install DT package if the package is not yet available in your R environment\nreadxl::read_excel(\"dataset/dataset-variable-description.xlsx\") |&gt; \n  DT::datatable()"
  },
  {
    "objectID": "00-m0-midterm-project.html#data-wrangling-and-management",
    "href": "00-m0-midterm-project.html#data-wrangling-and-management",
    "title": "Econ 148",
    "section": "Data wrangling and management",
    "text": "Data wrangling and management\n\nLibraries\n\n\n\n\n\n\nTask: Load the necessary libraries\n\n\n\nBefore we start working on the dataset, we need to load the necessary libraries that will be used for data wrangling, analysis and visualization. Make sure to load the following libraries here. For packages to be installed, you can use the install.packages function. There are packages to be installed later on this project, so make sure to install them as needed and load them here.\n\n\n\n# load all your libraries here\n\n\n\nData importation\n\n\n\n\n\n\nTask 2.1. Merging dataset\n\n\n\n\nImport the two dataset Employee.csv and PerformanceRating.csv. Save the Employee.csv as employee_dta and PerformanceRating.csv as perf_rating_dta.\nMerge the two dataset using the left_join function from dplyr. Use the EmployeeID variable as the varible to join by. You may read more information about the left_join function here.\nSave the merged dataset as hr_perf_dta and display the dataset using the datatable function from DT package.\n\n\n\n\n## import the two data here\n\n\n## merge employee_dta and perf_rating_dta using left_join function.\n## save the merged dataset as hr_perf_dta\n\n\n\n## Use the datatable from DT package to display the merged dataset\n\n\n\nData management\n\n\n\n\n\n\nTask 2.2. Standardizing variable names\n\n\n\n\nUsing the clean_names function from janitor package, standardize the variable names by using the recommended naming of variables.\nSave the renamed variables as hr_perf_dta to update the dataset.\n\n\n\n\n## clean names using the janitor packages and save as hr_perf_dta\n\n\n## display the renamed hr_perf_dta using datatable function\n\n\n\n\n\n\n\nTask 2.3. Recode data entries\n\n\n\n\nCreate a new variable cat_education wherein education is 1 = No formal education; 2 = High school; 3 = Bachelor; 4 = Masters; 5 = Doctorate. Use the case_when function to accomplish this task.\nSimilarly, create new variables cat_envi_sat, cat_job_sat, and cat_relation_sat for environment_satisfaction, job_satisfaction, and relationship_satisfaction, respectively. Re-code the values accordingly as 1 = Very dissatisfied; 2 = Dissatisfied; 3 = Neutral; 4 = Satisfied; and 5 = Very satisfied.\nCreate new variables cat_work_life_balance, cat_self_rating, cat_manager_rating for work_life_balance, self_rating, and manager_rating, respectively. Re-code accordingly as 1 = Unacceptable; 2 = Needs improvement; 3 = Meets expectation; 4 = Exceeds expectation; and 5 = Above and beyond.\nCreate a new variable bi_attrition by transforming attrition variable as a numeric variabe. Re-code accordingly as No = 0, and Yes = 1.\nSave all the changes in the hr_perf_dta. Note that saving the changes with the same name will update the dataset with the new variables created.\n\n\n\n\n## create cat_education\n\n\n\n## create cat_envi_sat,  cat_job_sat, and cat_relation_sat\n\n\n\n\n## create cat_work_life_balance, cat_self_rating, and cat_manager_rating\n\n\n\n\n\n## create bi_attrition\n\n\n\n## print the updated hr_perf_dta using datatable function"
  },
  {
    "objectID": "00-m0-midterm-project.html#exploratory-data-analysis",
    "href": "00-m0-midterm-project.html#exploratory-data-analysis",
    "title": "Econ 148",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\n\nDescriptive statistics of employee attrition\n\n\n\n\n\n\nTask 3.1. Breakdown of attrition by key variables\n\n\n\n\nSelect the variables attrition, job_role, department, age, salary, job_satisfaction, and work_life_balance. Save as attrition_key_var_dta.\nCompute and plot the attrition rate across job_role, department, and age, salary, job_satisfaction, and work_life_balance. To compute for the attrition rate, group the dataset by job role. Afterward, you can use the count function to get the frequency of attrition for each job role and then divide it by the total number of observations. Save the computation as pct_attrition. Do not forget to ungroup before storing the output. Store the output as attrition_rate_job_role.\nPlot for the attrition rate across job_role has been done for you! Study each line of code. You have the freedom to customize your plot accordingly. Show your creativity!\n\n\n\n\n## selecting attrition key variables and save as `attrition_key_var_dta`\n\n\n\n\n## compute the attrition rate across job_role and save as attrition_rate_job_role\n\n\n\n## print attrition_rate_job_role\n\n\n## Plot the attrition rate\n\n\n\nAnalysis of compensation and turnover\n\n\n\n\n\n\nTask 3.2. Analyzing compensation and turnover\n\n\n\n\nCompare the average monthly income of employees who left the company (bi_attrition = 1) and those who stayed (bi_attrition = 0). Use the t.test function to conduct a t-test and determine if there is a significant difference in average monthly income between the two groups. Save the results in a variable called attrition_ttest_results.\nInstall the report package and use the report function to generate a report of the t-test results.\nInstall the ggstatsplot package and use the ggbetweenstats function to visualize the distribution of monthly income for employees who left and those who stayed. Make sure to map the bi_attrition variable to the x argument and the salary variable to the y argument.\nVisualize the salary variable for employees who left and those who stayed using geom_histogram with geom_freqpoly. Make sure to facet the plot by the bi_attrition variable and apply alpha on the histogram plot.\nProvide recommendations on whether revising compensation policies could be an effective retention strategy.\n\n\n\n\n## compare the average monthly income of employees who left and those who stayed\n\n\n\n\n## print the results of the t-test\n\n\n## install the report package and use the report function to generate a report of the t-test results\n\n\n# install ggstatsplot package and use ggbetweenstats function to visualize the distribution of monthly income for employees who left and those who stayed\n\n\n# create histogram and frequency polygon of salary for employees who left and those who stayed\n\n\n\n\n\n\n\nDiscussion:\n\n\n\nProvide your discussion here.\n\n\n\n\nEmployee satisfaction and performance analysis\n\n\n\n\n\n\nTask 3.3. Analyzing employee satisfaction and performance\n\n\n\n\nAnalyze the average performance ratings (both ManagerRating and SelfRating) of employees who left vs. those who stayed. Use the group_by and count functions to calculate the average performance ratings for each group.\nVisualize the distribution of SelfRating for employees who left and those who stayed using a bar plot. Use the ggplot function to create the plot and map the SelfRating variable to the x argument and the bi_attrition variable to the fill argument.\nSimilarly, visualize the distribution of ManagerRating for employees who left and those who stayed using a bar plot. Make sure to map the ManagerRating variable to the x argument and the bi_attrition variable to the fill argument.\nCreate a boxplot of salary by job_satisfaction and bi_attrition to analyze the relationship between salary, job satisfaction, and attrition. Use the geom_boxplot function to create the plot and map the salary variable to the x argument, the job_satisfaction variable to the y argument, and the bi_attrition variable to the fill argument. You need to transform the job_satisfaction and bi_attrition variables into factors before creating the plot or within the ggplot function.\nDiscuss the results of the analysis and provide recommendations for HR interventions based on the findings.\n\n\n\n\n# Analyze the average performance ratings (both ManagerRating and SelfRating) of employees who left vs. those who stayed.\n\n\n# Visualize the distribution of SelfRating for employees who left and those who stayed using a bar plot.\n\n\n# Visualize the distribution of ManagerRating for employees who left and those who stayed using a bar plot.\n\n\n# create a boxplot of salary by job_satisfaction and bi_attrition to analyze the relationship between salary, job satisfaction, and attrition.\n\n\n\n\n\n\n\nDiscussion:\n\n\n\nProvide your discussion here.\n\n\n\n\nWork-life balance and retention strategies\n\n\n\n\n\n\nTask 3.4. Analyzing work-life balance and retention strategies\n\n\n\nAt this point, you are already well aware of the dataset and the possible factors that contribute to employee attrition. Using your R skills, accomplish the following tasks:\n\nAnalyze the distribution of WorkLifeBalance ratings for employees who left versus those who stayed.\nUse visualizations to show the differences.\nAssess whether employees with poor work-life balance are more likely to leave.\n\nYou have the freedom how you will accomplish this task. Be creative and provide insights that will help HR develop effective retention strategies."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Econ 148: Analytical and statistical packages for economics 1",
    "section": "",
    "text": "Class schedule: Monday & Tuesday | 17:00 - 18:00  Laboratory schedule: Wednesday | 16:00 - 19:00  Instructor: Christopher Llones  e-mail: christopher.llones@vsu.edu.ph  Pre-requisites: Econ 115 - Econometrics  Course credits: 3 units  Number of hours: 2 hrs lectures and 3 hrs laboratory per week \n\n\nCourse description\nIntroduction to survey research and survey data analysis using R programming.\n\n\nCourse objectives\n\nCreate a valid and reliable survey questionnaire and survey codebook.\nPerform exploratory data analysis on survey data using R programming.\nPerform Parametric and Non-Parametric Test on Means using R.\nPerform correlation analysis and build a regression model explaining relationship of certain economic variables in R.\nPerform regression analysis on limited dependent variables in R.\nPerform various techniques of multivariate data analysis in the R statistical software.\n\n\n\nCourse outline\n\n\n\n\n\n\n\n\n\nWeek\nTopics\nLessons\nDescription\n\n\n\n\nWeek 2-4\nModule 1: survey research design\n\nMethods of data collection\nSampling design in surveys\nMeasurement issues in survey research\nQuestionnaire construction\nBasics of interviewing\nCreating a codebook\nData entry\n\n\nDiscuss the various methods of data collection including survey, observation and experimental methods.\nDiscuss different ways for gathering a sample; random and non-random sampling. Discuss rudimentary formulas for sample size calculation.\nDiscuss the issues in assigning numbers to represent quantities of attributes. Discuss the various scales of measurement. Discuss criteria in constructing good measurement of variables: reliablity and validity.\nDiscuss the various advantages and disadvantages of interviews and questionnaire over other methods of data collection.\nDiscuss the do’s and dont’s of an interviewer’s conduct.\nDiscuss the importance of creating a codebook for survey data.\nDiscuss rudimentary of data entry.\n\n\n\nWeek 5-6\nModule 2: exploratory data analysis\n\nRudiments of EDA\nCharts and tables\nMeasures of central tendency\nDispersion, parameters, skewness and kurtosis\nContingency tables and scatter plot\n\n\nDiscuss EDA as the first step in data analysis.\nDiscuss various techniques in summarizing and visualizing data.\nDiscuss the various measures of central tendency and data location.\nDiscuss the relevance of various dispersion, parameters, skewness and kurtosis.\nDiscuss the relevance of contingency tables and scatterplots for summarizing and visualizing data.\n\n\n\nWeek 7-8\nModule 3: test on means\n\nParametric test on means\nNon-parametric test on means\n\n\nDiscuss the various t-tests and ANOVA and perform them on a sample data with R.\nPerform various non-parametric equivalent of the t-tests and ANOVA on sample data with R.\n\n\n\nWeek 9-11\nModule 4: correlation and regression analysis\n\nCorrelation analysis\nReview of Regression analysis\n\n\nDiscuss the various types of correlation analysis procedures. Interpret the correlation coefficient.\nDiscuss the various aspects of regression model building.\n\n\n\nWeek 12-15\nModule 5: limited-dependent variable models\n\nReview of binary dependent regression\nExtension to the logit model.\nCensored and truncated regression models.\nCount dependent variable models.\n\n\nDiscuss the various aspects of the logit and probit.\nDiscuss the multinomial and ordinal logit models.\nDiscuss the Tobit regression model for censored data and truncated regression models.\nDiscuss Poisson and Negative Binomial regression models in the regression analysis of count-dependent variable models.\n\n\n\nWeek 16-17\nModule 6: multivariate statistical analysis\n\nCluster analysis\nPrincipal component analysis\nExploratory factor analysis\nConfirmatory factor anlysis\nStructural equation modelling\n\n\nUnderstand and apply different clustering methods. Analyze and evaluate the quality and effectiveness of different clusters in dataset.\nLearn to perform and interpret principal component analysis to reduce the dimensionality of dataset. Develop the ability to identify and retain significant components for simplifying data without losing critical information.\nIdentify and estimate underlying factor structures within a set of observed variables.\nUnderstand model-based factor anlaysis and develop proficiency in evaluating model fit and making necessary adjustments to improve analysis.\nApply SEM techniques to understand relationships among variables and construct theoretical models.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "m2-intro-data-viz-ggplot.html",
    "href": "m2-intro-data-viz-ggplot.html",
    "title": "Module 2: Intro to data visualization using ggplot2",
    "section": "",
    "text": "The grammar of graphics\nDatasets and mapping\nGeometries\nStatistical transformation and plotting distribution\nPosition adjustment and scales\nCoordinates and themes\nFacets and custom plots\n\nView slides in new window\n\n\n\n\n\nPresentation keyboard shortcuts\n\n\n\nUse ← and → to navigate through the slides\n\n\nUse F to toggle full screen\n\n\nUse O to view an overview of all slides\n\n\nUse ? to see a list of other shortcuts",
    "crumbs": [
      "Topics",
      "Module 2: Intro to data visualization using ggplot2"
    ]
  },
  {
    "objectID": "m4-survey-research-design.html",
    "href": "m4-survey-research-design.html",
    "title": "Module 4: Survey research design",
    "section": "",
    "text": "Methods of data collection\nSampling desing in surveys\nMeasurement issues in survey research\nQuestionnaire construction\nBasics of interviewing\nCreating codebook\nData entry\n\nView slides in new window\n\n\n\n\n\nPresentation keyboard shortcuts\n\n\n\nUse ← and → to navigate through the slides\n\n\nUse F to toggle full screen\n\n\nUse O to view an overview of all slides\n\n\nUse ? to see a list of other shortcuts"
  },
  {
    "objectID": "m6-test-means.html",
    "href": "m6-test-means.html",
    "title": "Module 6: Tests on means and chi-square test",
    "section": "",
    "text": "Introduction to hypothesis testing\nParametric vs non-parametric tests\nIndependent samples t-test\nPaired samples t-test\nOne-way ANOVA\nChi-square test\n\nView slides in new window\n\n\n\n\n\n\n\n\n\n\nPresentation keyboard shortcuts\n\n\n\n\n\n\nUse ← and → to navigate through the slides\n\n\nUse F to toggle full screen\n\n\nUse O to view an overview of all slides\n\n\nUse ? to see a list of other shortcuts"
  }
]